{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando as bibilotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "try:\n",
    "    import keras\n",
    "except ImportError:\n",
    "    raise ImportError(\"Instale keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acertos_sujeito_1.csv',\n",
       " 'acertos_sujeito_2.csv',\n",
       " 'acertos_sujeito_3.csv',\n",
       " 'acertos_sujeito_4.csv',\n",
       " 'acertos_sujeito_5.csv',\n",
       " 'acertos_sujeito_6.csv',\n",
       " 'acertos_sujeito_7.csv',\n",
       " 'erros_sujeito_1.csv',\n",
       " 'erros_sujeito_2.csv',\n",
       " 'erros_sujeito_3.csv',\n",
       " 'erros_sujeito_4.csv',\n",
       " 'erros_sujeito_5.csv',\n",
       " 'erros_sujeito_6.csv',\n",
       " 'erros_sujeito_7.csv',\n",
       " 'Explicação.JPG',\n",
       " 'frequências.csv',\n",
       " 'tempos.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nome_de_instancias = os.listdir(\"./EEG_Machine_Learning/\")\n",
    "nome_de_instancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "acertos = []\n",
    "erros = []\n",
    "for i in range(7):\n",
    "    acertos.append(\"./EEG_Machine_Learning/\" + nome_de_instancias[i])\n",
    "    erros.append(\"./EEG_Machine_Learning/\" + nome_de_instancias[7 + i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['./EEG_Machine_Learning/acertos_sujeito_1.csv',\n",
       "  './EEG_Machine_Learning/acertos_sujeito_2.csv',\n",
       "  './EEG_Machine_Learning/acertos_sujeito_3.csv',\n",
       "  './EEG_Machine_Learning/acertos_sujeito_4.csv',\n",
       "  './EEG_Machine_Learning/acertos_sujeito_5.csv',\n",
       "  './EEG_Machine_Learning/acertos_sujeito_6.csv',\n",
       "  './EEG_Machine_Learning/acertos_sujeito_7.csv'],\n",
       " ['./EEG_Machine_Learning/erros_sujeito_1.csv',\n",
       "  './EEG_Machine_Learning/erros_sujeito_2.csv',\n",
       "  './EEG_Machine_Learning/erros_sujeito_3.csv',\n",
       "  './EEG_Machine_Learning/erros_sujeito_4.csv',\n",
       "  './EEG_Machine_Learning/erros_sujeito_5.csv',\n",
       "  './EEG_Machine_Learning/erros_sujeito_6.csv',\n",
       "  './EEG_Machine_Learning/erros_sujeito_7.csv'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acertos, erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sujeito1_acertos = pd.read_csv(acertos[0], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Columns: 61050 entries, 0 to 61049\n",
      "dtypes: float64(60341), int64(709)\n",
      "memory usage: 93.2 MB\n"
     ]
    }
   ],
   "source": [
    "dataset_sujeito1_acertos.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adicionando uma coluna chamada y no final da dataset, considerando que y é os acertos == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sujeito1_acertos.insert(61050, \"y\", [1 for i in range(200)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>61041</th>\n",
       "      <th>61042</th>\n",
       "      <th>61043</th>\n",
       "      <th>61044</th>\n",
       "      <th>61045</th>\n",
       "      <th>61046</th>\n",
       "      <th>61047</th>\n",
       "      <th>61048</th>\n",
       "      <th>61049</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>294800.0</td>\n",
       "      <td>239080.0</td>\n",
       "      <td>187360.0</td>\n",
       "      <td>141290.0</td>\n",
       "      <td>102160.0</td>\n",
       "      <td>70457.0</td>\n",
       "      <td>46156.0</td>\n",
       "      <td>29034.0</td>\n",
       "      <td>18499.0</td>\n",
       "      <td>13866.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2676.5</td>\n",
       "      <td>14353.0</td>\n",
       "      <td>16057.0</td>\n",
       "      <td>676.96</td>\n",
       "      <td>23396.0</td>\n",
       "      <td>10872.0</td>\n",
       "      <td>1490.4</td>\n",
       "      <td>39833.0</td>\n",
       "      <td>78535.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>291110.0</td>\n",
       "      <td>237100.0</td>\n",
       "      <td>186500.0</td>\n",
       "      <td>141270.0</td>\n",
       "      <td>102770.0</td>\n",
       "      <td>71580.0</td>\n",
       "      <td>47712.0</td>\n",
       "      <td>30860.0</td>\n",
       "      <td>20447.0</td>\n",
       "      <td>15844.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2776.4</td>\n",
       "      <td>14047.0</td>\n",
       "      <td>16497.0</td>\n",
       "      <td>1121.50</td>\n",
       "      <td>23249.0</td>\n",
       "      <td>9840.2</td>\n",
       "      <td>2175.1</td>\n",
       "      <td>39812.0</td>\n",
       "      <td>77100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 61051 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4        5        6  \\\n",
       "198  294800.0  239080.0  187360.0  141290.0  102160.0  70457.0  46156.0   \n",
       "199  291110.0  237100.0  186500.0  141270.0  102770.0  71580.0  47712.0   \n",
       "\n",
       "           7        8        9 ...   61041    61042    61043    61044  \\\n",
       "198  29034.0  18499.0  13866.0 ...  2676.5  14353.0  16057.0   676.96   \n",
       "199  30860.0  20447.0  15844.0 ...  2776.4  14047.0  16497.0  1121.50   \n",
       "\n",
       "       61045    61046   61047    61048    61049  y  \n",
       "198  23396.0  10872.0  1490.4  39833.0  78535.0  1  \n",
       "199  23249.0   9840.2  2175.1  39812.0  77100.0  1  \n",
       "\n",
       "[2 rows x 61051 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sujeito1_acertos.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realizando a mesma coisa, com a tabela de erros do sujeito 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sujeito1_erros = pd.read_csv(erros[0], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Columns: 61050 entries, 0 to 61049\n",
      "dtypes: float64(60388), int64(662)\n",
      "memory usage: 93.2 MB\n"
     ]
    }
   ],
   "source": [
    "dataset_sujeito1_erros.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adicionando uma coluna chamada y no final da dataset, considerando que y   é erros == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sujeito1_erros.insert(61050, \"y\", [0 for i in range(200)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>61041</th>\n",
       "      <th>61042</th>\n",
       "      <th>61043</th>\n",
       "      <th>61044</th>\n",
       "      <th>61045</th>\n",
       "      <th>61046</th>\n",
       "      <th>61047</th>\n",
       "      <th>61048</th>\n",
       "      <th>61049</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>36201.0</td>\n",
       "      <td>18307.0</td>\n",
       "      <td>7888.7</td>\n",
       "      <td>4254.3</td>\n",
       "      <td>6540.6</td>\n",
       "      <td>14729.0</td>\n",
       "      <td>30880.0</td>\n",
       "      <td>60106.0</td>\n",
       "      <td>109850.0</td>\n",
       "      <td>187790.0</td>\n",
       "      <td>...</td>\n",
       "      <td>80243.0</td>\n",
       "      <td>103930.0</td>\n",
       "      <td>62724.0</td>\n",
       "      <td>16285.0</td>\n",
       "      <td>14298.0</td>\n",
       "      <td>75997.0</td>\n",
       "      <td>69035.0</td>\n",
       "      <td>31203.0</td>\n",
       "      <td>13311.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>36255.0</td>\n",
       "      <td>17826.0</td>\n",
       "      <td>6949.6</td>\n",
       "      <td>3088.5</td>\n",
       "      <td>5505.9</td>\n",
       "      <td>14265.0</td>\n",
       "      <td>31525.0</td>\n",
       "      <td>62373.0</td>\n",
       "      <td>114240.0</td>\n",
       "      <td>194640.0</td>\n",
       "      <td>...</td>\n",
       "      <td>81836.0</td>\n",
       "      <td>103750.0</td>\n",
       "      <td>59483.0</td>\n",
       "      <td>13776.0</td>\n",
       "      <td>11769.0</td>\n",
       "      <td>73896.0</td>\n",
       "      <td>65869.0</td>\n",
       "      <td>27863.0</td>\n",
       "      <td>10841.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 61051 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0        1       2       3       4        5        6        7  \\\n",
       "198  36201.0  18307.0  7888.7  4254.3  6540.6  14729.0  30880.0  60106.0   \n",
       "199  36255.0  17826.0  6949.6  3088.5  5505.9  14265.0  31525.0  62373.0   \n",
       "\n",
       "            8         9 ...    61041     61042    61043    61044    61045  \\\n",
       "198  109850.0  187790.0 ...  80243.0  103930.0  62724.0  16285.0  14298.0   \n",
       "199  114240.0  194640.0 ...  81836.0  103750.0  59483.0  13776.0  11769.0   \n",
       "\n",
       "       61046    61047    61048    61049  y  \n",
       "198  75997.0  69035.0  31203.0  13311.0  0  \n",
       "199  73896.0  65869.0  27863.0  10841.0  0  \n",
       "\n",
       "[2 rows x 61051 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sujeito1_erros.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unindo os erros com os acertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sujeito1_acertos_erros = dataset_sujeito1_acertos.append(dataset_sujeito1_erros, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Columns: 61051 entries, 0 to y\n",
      "dtypes: float64(61030), int64(21)\n",
      "memory usage: 186.3 MB\n"
     ]
    }
   ],
   "source": [
    "dataset_sujeito1_acertos_erros.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>61041</th>\n",
       "      <th>61042</th>\n",
       "      <th>61043</th>\n",
       "      <th>61044</th>\n",
       "      <th>61045</th>\n",
       "      <th>61046</th>\n",
       "      <th>61047</th>\n",
       "      <th>61048</th>\n",
       "      <th>61049</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>301840.0</td>\n",
       "      <td>242660.0</td>\n",
       "      <td>188630.0</td>\n",
       "      <td>140950.0</td>\n",
       "      <td>100420.0</td>\n",
       "      <td>67514.0</td>\n",
       "      <td>42370.0</td>\n",
       "      <td>24659.0</td>\n",
       "      <td>13852.0</td>\n",
       "      <td>9225.7</td>\n",
       "      <td>...</td>\n",
       "      <td>2367.5</td>\n",
       "      <td>15087.0</td>\n",
       "      <td>15799.0</td>\n",
       "      <td>1022.50</td>\n",
       "      <td>24729.0</td>\n",
       "      <td>13779.0</td>\n",
       "      <td>230.81</td>\n",
       "      <td>39910.00</td>\n",
       "      <td>80428.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>300050.0</td>\n",
       "      <td>241840.0</td>\n",
       "      <td>188370.0</td>\n",
       "      <td>141110.0</td>\n",
       "      <td>100980.0</td>\n",
       "      <td>68402.0</td>\n",
       "      <td>43476.0</td>\n",
       "      <td>25926.0</td>\n",
       "      <td>15217.0</td>\n",
       "      <td>10562.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2456.8</td>\n",
       "      <td>14901.0</td>\n",
       "      <td>15730.0</td>\n",
       "      <td>695.92</td>\n",
       "      <td>24180.0</td>\n",
       "      <td>12901.0</td>\n",
       "      <td>506.90</td>\n",
       "      <td>39847.00</td>\n",
       "      <td>80049.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>297220.0</td>\n",
       "      <td>240400.0</td>\n",
       "      <td>187850.0</td>\n",
       "      <td>141260.0</td>\n",
       "      <td>101680.0</td>\n",
       "      <td>69580.0</td>\n",
       "      <td>44995.0</td>\n",
       "      <td>27680.0</td>\n",
       "      <td>17069.0</td>\n",
       "      <td>12437.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2581.1</td>\n",
       "      <td>14607.0</td>\n",
       "      <td>15835.0</td>\n",
       "      <td>562.51</td>\n",
       "      <td>23655.0</td>\n",
       "      <td>11733.0</td>\n",
       "      <td>1021.30</td>\n",
       "      <td>39837.00</td>\n",
       "      <td>79279.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>294800.0</td>\n",
       "      <td>239080.0</td>\n",
       "      <td>187360.0</td>\n",
       "      <td>141290.0</td>\n",
       "      <td>102160.0</td>\n",
       "      <td>70457.0</td>\n",
       "      <td>46156.0</td>\n",
       "      <td>29034.0</td>\n",
       "      <td>18499.0</td>\n",
       "      <td>13866.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2676.5</td>\n",
       "      <td>14353.0</td>\n",
       "      <td>16057.0</td>\n",
       "      <td>676.96</td>\n",
       "      <td>23396.0</td>\n",
       "      <td>10872.0</td>\n",
       "      <td>1490.40</td>\n",
       "      <td>39833.00</td>\n",
       "      <td>78535.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>291110.0</td>\n",
       "      <td>237100.0</td>\n",
       "      <td>186500.0</td>\n",
       "      <td>141270.0</td>\n",
       "      <td>102770.0</td>\n",
       "      <td>71580.0</td>\n",
       "      <td>47712.0</td>\n",
       "      <td>30860.0</td>\n",
       "      <td>20447.0</td>\n",
       "      <td>15844.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2776.4</td>\n",
       "      <td>14047.0</td>\n",
       "      <td>16497.0</td>\n",
       "      <td>1121.50</td>\n",
       "      <td>23249.0</td>\n",
       "      <td>9840.2</td>\n",
       "      <td>2175.10</td>\n",
       "      <td>39812.00</td>\n",
       "      <td>77100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>498470.0</td>\n",
       "      <td>332970.0</td>\n",
       "      <td>206900.0</td>\n",
       "      <td>116760.0</td>\n",
       "      <td>60018.0</td>\n",
       "      <td>36551.0</td>\n",
       "      <td>48726.0</td>\n",
       "      <td>100770.0</td>\n",
       "      <td>196600.0</td>\n",
       "      <td>337630.0</td>\n",
       "      <td>...</td>\n",
       "      <td>196120.0</td>\n",
       "      <td>158650.0</td>\n",
       "      <td>78389.0</td>\n",
       "      <td>35573.00</td>\n",
       "      <td>40533.0</td>\n",
       "      <td>55222.0</td>\n",
       "      <td>28279.00</td>\n",
       "      <td>2578.30</td>\n",
       "      <td>5557.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>523900.0</td>\n",
       "      <td>353750.0</td>\n",
       "      <td>223510.0</td>\n",
       "      <td>129770.0</td>\n",
       "      <td>70596.0</td>\n",
       "      <td>45880.0</td>\n",
       "      <td>57884.0</td>\n",
       "      <td>110460.0</td>\n",
       "      <td>207140.0</td>\n",
       "      <td>348420.0</td>\n",
       "      <td>...</td>\n",
       "      <td>193130.0</td>\n",
       "      <td>156020.0</td>\n",
       "      <td>76951.0</td>\n",
       "      <td>34562.00</td>\n",
       "      <td>40123.0</td>\n",
       "      <td>55283.0</td>\n",
       "      <td>28184.00</td>\n",
       "      <td>2110.90</td>\n",
       "      <td>6000.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>550610.0</td>\n",
       "      <td>375760.0</td>\n",
       "      <td>241300.0</td>\n",
       "      <td>144060.0</td>\n",
       "      <td>82481.0</td>\n",
       "      <td>56456.0</td>\n",
       "      <td>68228.0</td>\n",
       "      <td>121250.0</td>\n",
       "      <td>218530.0</td>\n",
       "      <td>359860.0</td>\n",
       "      <td>...</td>\n",
       "      <td>189690.0</td>\n",
       "      <td>152950.0</td>\n",
       "      <td>75266.0</td>\n",
       "      <td>33282.00</td>\n",
       "      <td>39567.0</td>\n",
       "      <td>55192.0</td>\n",
       "      <td>28118.00</td>\n",
       "      <td>1678.90</td>\n",
       "      <td>6407.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>588070.0</td>\n",
       "      <td>406850.0</td>\n",
       "      <td>266830.0</td>\n",
       "      <td>165220.0</td>\n",
       "      <td>100370.0</td>\n",
       "      <td>72605.0</td>\n",
       "      <td>83908.0</td>\n",
       "      <td>137360.0</td>\n",
       "      <td>235090.0</td>\n",
       "      <td>376020.0</td>\n",
       "      <td>...</td>\n",
       "      <td>184220.0</td>\n",
       "      <td>148500.0</td>\n",
       "      <td>72808.0</td>\n",
       "      <td>31184.00</td>\n",
       "      <td>38628.0</td>\n",
       "      <td>54880.0</td>\n",
       "      <td>28006.00</td>\n",
       "      <td>1153.20</td>\n",
       "      <td>6966.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>617310.0</td>\n",
       "      <td>431770.0</td>\n",
       "      <td>287490.0</td>\n",
       "      <td>182570.0</td>\n",
       "      <td>115380.0</td>\n",
       "      <td>86251.0</td>\n",
       "      <td>97144.0</td>\n",
       "      <td>150760.0</td>\n",
       "      <td>248560.0</td>\n",
       "      <td>388960.0</td>\n",
       "      <td>...</td>\n",
       "      <td>179560.0</td>\n",
       "      <td>144840.0</td>\n",
       "      <td>70717.0</td>\n",
       "      <td>29331.00</td>\n",
       "      <td>37733.0</td>\n",
       "      <td>54540.0</td>\n",
       "      <td>27943.00</td>\n",
       "      <td>809.29</td>\n",
       "      <td>7394.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 61051 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4        5        6  \\\n",
       "195  301840.0  242660.0  188630.0  140950.0  100420.0  67514.0  42370.0   \n",
       "196  300050.0  241840.0  188370.0  141110.0  100980.0  68402.0  43476.0   \n",
       "197  297220.0  240400.0  187850.0  141260.0  101680.0  69580.0  44995.0   \n",
       "198  294800.0  239080.0  187360.0  141290.0  102160.0  70457.0  46156.0   \n",
       "199  291110.0  237100.0  186500.0  141270.0  102770.0  71580.0  47712.0   \n",
       "200  498470.0  332970.0  206900.0  116760.0   60018.0  36551.0  48726.0   \n",
       "201  523900.0  353750.0  223510.0  129770.0   70596.0  45880.0  57884.0   \n",
       "202  550610.0  375760.0  241300.0  144060.0   82481.0  56456.0  68228.0   \n",
       "203  588070.0  406850.0  266830.0  165220.0  100370.0  72605.0  83908.0   \n",
       "204  617310.0  431770.0  287490.0  182570.0  115380.0  86251.0  97144.0   \n",
       "\n",
       "            7         8         9 ...     61041     61042    61043     61044  \\\n",
       "195   24659.0   13852.0    9225.7 ...    2367.5   15087.0  15799.0   1022.50   \n",
       "196   25926.0   15217.0   10562.0 ...    2456.8   14901.0  15730.0    695.92   \n",
       "197   27680.0   17069.0   12437.0 ...    2581.1   14607.0  15835.0    562.51   \n",
       "198   29034.0   18499.0   13866.0 ...    2676.5   14353.0  16057.0    676.96   \n",
       "199   30860.0   20447.0   15844.0 ...    2776.4   14047.0  16497.0   1121.50   \n",
       "200  100770.0  196600.0  337630.0 ...  196120.0  158650.0  78389.0  35573.00   \n",
       "201  110460.0  207140.0  348420.0 ...  193130.0  156020.0  76951.0  34562.00   \n",
       "202  121250.0  218530.0  359860.0 ...  189690.0  152950.0  75266.0  33282.00   \n",
       "203  137360.0  235090.0  376020.0 ...  184220.0  148500.0  72808.0  31184.00   \n",
       "204  150760.0  248560.0  388960.0 ...  179560.0  144840.0  70717.0  29331.00   \n",
       "\n",
       "       61045    61046     61047     61048    61049  y  \n",
       "195  24729.0  13779.0    230.81  39910.00  80428.0  1  \n",
       "196  24180.0  12901.0    506.90  39847.00  80049.0  1  \n",
       "197  23655.0  11733.0   1021.30  39837.00  79279.0  1  \n",
       "198  23396.0  10872.0   1490.40  39833.00  78535.0  1  \n",
       "199  23249.0   9840.2   2175.10  39812.00  77100.0  1  \n",
       "200  40533.0  55222.0  28279.00   2578.30   5557.0  0  \n",
       "201  40123.0  55283.0  28184.00   2110.90   6000.5  0  \n",
       "202  39567.0  55192.0  28118.00   1678.90   6407.6  0  \n",
       "203  38628.0  54880.0  28006.00   1153.20   6966.0  0  \n",
       "204  37733.0  54540.0  27943.00    809.29   7394.1  0  \n",
       "\n",
       "[10 rows x 61051 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sujeito1_acertos_erros.tail(205).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0]), (400,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset_sujeito1_acertos_erros.iloc[:, :-1].values\n",
    "y = dataset_sujeito1_acertos_erros.iloc[:, -1].values\n",
    "y, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (400,)\n",
      "integer_encoded: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (400,)\n",
      "onehot_encoded: [[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]] (400, 2)\n",
      "inverted: [1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# define example\n",
    "data = np.array(y)\n",
    "values = np.array(data)\n",
    "print(\"Values: \", values, values.shape)\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "print(\"integer_encoded:\", integer_encoded, integer_encoded.shape)\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(categories=\"auto\", sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(\"onehot_encoded:\", onehot_encoded,  onehot_encoded.shape)\n",
    "# invert first example\n",
    "inverted = label_encoder.inverse_transform([np.argmax(onehot_encoded[0, :])])\n",
    "print(\"inverted:\", inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.] 1\n",
      "[0. 1.] 1\n",
      "[1. 0.] 0\n"
     ]
    }
   ],
   "source": [
    "print(onehot_encoded[4], values[4])\n",
    "print(onehot_encoded[43], values[43])\n",
    "print(onehot_encoded[200], values[200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separando dataset em treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, onehot_encoded, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80, 2), (320, 2))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape , y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rodando Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.utils import plot_model, print_summary\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inicializando a Rede Neural\n",
    "classifier = Sequential()\n",
    "# Adicionando a camada inicial\n",
    "classifier.add(Dense(1024, activation=\"relu\", name=\"Input_1\"))\n",
    "\n",
    "# Prevent Overfitting\n",
    "#classifier.add(Dropout(0.01))\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(1024, activation=\"tanh\", name=\"Hidden_1_tanh\"))\n",
    "\n",
    "classifier.add(Dense(128, activation=\"relu\", name=\"Hiddden_2_relu\"))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(2, activation=\"softmax\", name=\"Output_softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling Neural Network\n",
    "classifier.compile(optimizer = 'adam',\n",
    "                   loss = 'categorical_crossentropy',\n",
    "                   metrics = ['accuracy', ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logs/2018-10-28_18:04:43.753757'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_logs = \"logs/{}\".format(datetime.datetime.now())\n",
    "name_logs.replace(\" \", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbCallBack = TensorBoard(log_dir=name_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((320, 61050), (320, 2))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 256 samples, validate on 64 samples\n",
      "Epoch 1/10\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 1.0476 - acc: 0.4922 - val_loss: 0.7706 - val_acc: 0.5156\n",
      "Epoch 2/10\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 0.8009 - acc: 0.5664 - val_loss: 0.5817 - val_acc: 0.7812\n",
      "Epoch 3/10\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 0.6072 - acc: 0.6406 - val_loss: 0.8051 - val_acc: 0.4844\n",
      "Epoch 4/10\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 0.7062 - acc: 0.5898 - val_loss: 0.9037 - val_acc: 0.4844\n",
      "Epoch 5/10\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 0.5943 - acc: 0.6953 - val_loss: 0.5942 - val_acc: 0.5938\n",
      "Epoch 6/10\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 0.4659 - acc: 0.7617 - val_loss: 0.5370 - val_acc: 0.5938\n",
      "Epoch 7/10\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 0.4342 - acc: 0.7891 - val_loss: 0.5370 - val_acc: 0.5625\n",
      "Epoch 8/10\n",
      "256/256 [==============================] - 8s 32ms/step - loss: 0.4134 - acc: 0.8398 - val_loss: 0.4733 - val_acc: 0.7812\n",
      "Epoch 9/10\n",
      "256/256 [==============================] - 8s 31ms/step - loss: 0.3763 - acc: 0.8242 - val_loss: 0.4502 - val_acc: 0.8281\n",
      "Epoch 10/10\n",
      "256/256 [==============================] - 8s 31ms/step - loss: 0.3669 - acc: 0.8633 - val_loss: 0.4968 - val_acc: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f189de62550>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting our model \n",
    "classifier.fit(X_train, y_train, epochs=10, validation_split=0.2 , verbose=1, callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_1 (Dense)              (None, 1024)              62516224  \n",
      "_________________________________________________________________\n",
      "Hidden_1_tanh (Dense)        (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "Hiddden_2_relu (Dense)       (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "Output_softmax (Dense)       (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 63,697,282\n",
      "Trainable params: 63,697,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.utils.print_summary(classifier, line_length=None, positions=None, print_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4299091696739197, 0.8125]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if input(' Reset keras? (y/n) \\n') == 'y':\n",
    "    keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matriz de Confusão\n",
    "Para fazer a matriz de confusão precisa de 3 arrays:\n",
    "\n",
    "* X_test que contém os valores dos atributos\n",
    "* y_pred que contém os valores previstos pela rede (1D)\n",
    "* y_test que contém os valores reais que se correlacionam com X_test (1D)\n",
    "\n",
    "Porém o y_pred e o y_test estão no formato de One Hot Encoding, então precisamos convertê-lo para o original\n",
    "\n",
    "Predizendo os valores a partir de X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inverted len: 80\n",
      "y_pred:  [[0.09919301 0.90080696]\n",
      " [0.19236083 0.8076392 ]\n",
      " [0.2657934  0.73420656]\n",
      " [0.1794155  0.8205845 ]\n",
      " [0.9635433  0.0364567 ]\n",
      " [0.15722324 0.8427768 ]\n",
      " [0.1794155  0.8205845 ]\n",
      " [0.19236083 0.8076392 ]\n",
      " [0.4690305  0.53096944]\n",
      " [0.16345571 0.8365442 ]\n",
      " [0.87579244 0.1242076 ]\n",
      " [0.09919301 0.90080696]\n",
      " [0.9225266  0.07747339]\n",
      " [0.87579244 0.1242076 ]\n",
      " [0.09919301 0.90080696]\n",
      " [0.14621434 0.85378563]\n",
      " [0.09919301 0.90080696]\n",
      " [0.43368912 0.5663108 ]\n",
      " [0.33807003 0.66192997]\n",
      " [0.09919301 0.90080696]\n",
      " [0.09919301 0.90080696]\n",
      " [0.16345571 0.8365442 ]\n",
      " [0.20385167 0.7961483 ]\n",
      " [0.09919301 0.90080696]\n",
      " [0.16345571 0.8365442 ]\n",
      " [0.16345571 0.8365442 ]\n",
      " [0.09919301 0.90080696]\n",
      " [0.9108009  0.08919911]\n",
      " [0.09919301 0.90080696]\n",
      " [0.09919301 0.90080696]\n",
      " [0.10710558 0.8928944 ]\n",
      " [0.09919301 0.90080696]\n",
      " [0.10710558 0.8928944 ]\n",
      " [0.1794155  0.8205845 ]\n",
      " [0.91007566 0.08992433]\n",
      " [0.2657934  0.73420656]\n",
      " [0.90804726 0.09195267]\n",
      " [0.1794155  0.8205845 ]\n",
      " [0.7821656  0.21783441]\n",
      " [0.7515545  0.24844544]\n",
      " [0.1794155  0.8205845 ]\n",
      " [0.87579244 0.1242076 ]\n",
      " [0.1794155  0.8205845 ]\n",
      " [0.1794155  0.8205845 ]\n",
      " [0.20385167 0.7961483 ]\n",
      " [0.2657934  0.73420656]\n",
      " [0.7821656  0.21783441]\n",
      " [0.16345571 0.8365442 ]\n",
      " [0.94587386 0.05412617]\n",
      " [0.7821656  0.21783441]\n",
      " [0.90804726 0.09195267]\n",
      " [0.2657934  0.73420656]\n",
      " [0.09919301 0.90080696]\n",
      " [0.09919301 0.90080696]\n",
      " [0.20385167 0.7961483 ]\n",
      " [0.2657934  0.73420656]\n",
      " [0.43368912 0.5663108 ]\n",
      " [0.2657934  0.73420656]\n",
      " [0.8583019  0.14169817]\n",
      " [0.1794155  0.8205845 ]\n",
      " [0.9635433  0.0364567 ]\n",
      " [0.09919301 0.90080696]\n",
      " [0.8583019  0.14169817]\n",
      " [0.71996886 0.28003114]\n",
      " [0.91309667 0.0869034 ]\n",
      " [0.87579244 0.1242076 ]\n",
      " [0.2657934  0.73420656]\n",
      " [0.1794155  0.8205845 ]\n",
      " [0.16345571 0.8365442 ]\n",
      " [0.09919301 0.90080696]\n",
      " [0.7515545  0.24844544]\n",
      " [0.91256285 0.0874372 ]\n",
      " [0.1794155  0.8205845 ]\n",
      " [0.1794155  0.8205845 ]\n",
      " [0.09919301 0.90080696]\n",
      " [0.1794155  0.8205845 ]\n",
      " [0.2657934  0.73420656]\n",
      " [0.9465658  0.0534342 ]\n",
      " [0.09919301 0.90080696]\n",
      " [0.2657934  0.73420656]] (80, 2)\n"
     ]
    }
   ],
   "source": [
    "inverted_y_pred = list()\n",
    "for i in range(len(y_pred)):\n",
    "    inverted_y_pred.append(int(label_encoder.inverse_transform([np.argmax(y_pred[i])])))\n",
    "print(\"inverted len:\", len(inverted_y_pred))\n",
    "print(\"y_pred: \", y_pred, y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inverted len: 80\n",
      "y_pred:  [[0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]] (80, 2)\n"
     ]
    }
   ],
   "source": [
    "inverted_y_test = list()\n",
    "for i in range(len(y_test)):\n",
    "    inverted_y_test.append(int(label_encoder.inverse_transform([np.argmax(y_test[i])])))\n",
    "print(\"inverted len:\", len(inverted_y_test))\n",
    "print(\"y_pred: \", y_test, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inverted: [1]\n"
     ]
    }
   ],
   "source": [
    "inverted = label_encoder.inverse_transform([np.argmax(y_pred[0, :])]) #onehot_encoded[0, :])])\n",
    "print(\"inverted:\", inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23, 15],\n",
       "       [ 0, 42]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Sintaxe da função\n",
    "# sklearn.metrics.confusion_matrix(y_true, y_pred, labels=None, sample_weight=None)\n",
    "matrix = confusion_matrix(inverted_y_test, inverted_y_pred)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como utilizamos uma classificação binária, temos que os verdadeiros-negativos é $C_{00}$, falso-negativo é $C_{10}$, verdadeiros-positivos $C_{11}$ e falso-positivos é $C_{01}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_1",
   "language": "python",
   "name": "tensorflow_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
